Occam's Razor	Heuristic stating that the simplest explanation for a phenomenon is often the best
Rejection Region	Subset of possible null hypothesis outcomes  with probabilities falling under a low probability threshold, e.g. outcomes with a null-distribution probability < 0.05
Test Statistic	Metric for measuring how well a null hypothesis fits the data
Null Hypothesis	Hypothesis that no difference exists between certain groups of events/outcomes.
Null Distribution	Distribution of possible outcomes of an event, given that the null hypothesis is true
Rejection Region	Subset of null distribution with outcomes under a low, pre-determined probability threshold; if an outcome falls within this region (e.g. p < 0.05), it suggests that the null hypothesis is not true.
Alternative Hypothesis	A hypothesis providing a different probability distribution than the null hypothesis; conceptually, holds that some difference from the null hypothesis exists (e.g. different means, frequencies, trends)
Significance Level/False Positive Rate/Type I error	Probability of falsely rejecting the null hypothesis due to outcomes falling within the rejection region by chance; in terms of the null distribution, total probability that the outcome could fall within the rejection region given that the null hypothesis is true.
Power	True positive rate of a test (i.e. probability that an outcome falls in the rejection region of the null distribution, given that the alternative hypothesis is true)
False Negative Rate/Type II Error	Probability of falsely failing to reject the null hypothesis when an outcome from the alternative hypothesis distribution fails to fall within the rejection region of the null hypothesis.
Specificity	Complement of false positive rate; probability of a test not having a Type I error
Power/Sensitivity/True Negative Rate	complement of false negative rate (Type II error); chance of correctly rejecting null hypothesis if an outcome falls in the rejection region of the null distribution.
Assumption of independence	Treating every observation in a dataset as if it has no influence on the outcomes of other observations (or at least none unaccounted-for in the model).
P-Value Hacking	"Fallaciously ""fishing"" for significant results by running tests until a small p-value is obtained by chance; this can be a deliberate, or inadvertently caused by a scattershot approach to testing."
Hypothesis Switching	Fallacy of generating and/or changing hypotheses for a set of known results until a significant result is obtained by chance.
Family Wide Error Rate (FWER)	Probability of at least one false positive occurring in repeated tests. Assuming independent observations, this is the completement of the probability of only true positives occurring, and approaches 1.0 as the number of trials approaches infinity.
P-Value Histogram	Visualization to get a quick sense of p-value distribution of possible test outcomes for a null hypothesis. The distribution is a mixture of cases where the null hypothesis is rejected (small p-values) or retained (larger p-values).
False Discovery Rate(FDR)	The proportion of false positives among all cases where the null hypothesis is rejected across an entire distribution.
Local False Discovery Rate (fdr)	The probability of Type I Error at a given p-value when the distribution of the p-values is treated as a mixture model of the null distribution and alternative hypothesis distribution. This varies based on the p-value, rather than being a property of the entire distribution.
Tail Area False Disovery Rate (Fdr)	Integration-based extension of the local False Discovery Rate to obtain a false discovery rate for the entire distribution.
Independent Filtering	Method to increase test power by filtering variables with criteria that are independent under the null hypothesis, but correlated under the alternative (per Bourbon, Wolfgang, and Huber 2010)
Independent Hypothesis Weighting	A method of improving power of multiple testing by weighting hypotheses based on their power
Bonferroni Adjustment	Method used to compensate for inflated Type I (false positive) error in multiple testing by dividing the critical value (e.g. p = 0.05) by the number of comparisons performed
whole genome sequencing	Method used to determine and record the DNA base values and order across all of an organism's genes
marker gene	A gene used to determine membership in a group of interest (e.g. a taxon, genotype within a population, or possessing a certain metabolic trait)
expression level	The realtive abundance of transcriptions of a gene of interest present in e.g. a cell or environment
reagent	a compound used in creating a chemical reaction like an assay
hypothesis testing	Evaluating whether test outcomes are sufficently unlikely under the null hypothesis (holding that outcomes are determined fully by chance) that it can be rejected in favor of an alternative hypothesis
workflow	A sequence of steps used in carrying out a larger operation or process
two-sided test	A statistical test which can reject the null hypothesis if an observed value is either larger or smaller than that expected under the null hypothesis
one-sided test	A statistical test which can reject the null hypothesis if an observed value departs from the expected range in a single, predetermined direction (i.e. larger or smaller)
two-sample	In the context of statistical testing, comparing the means of two groups
unpaired	In the context of statistical tests, these are used when comparing groups with independent measurements (e.g. not comparing the same individuals under two conditions)
equal variances	When groups being compared have (substantially) equivalent degrees of variance
dependence	When the outcomes of two variables are statistically correlated
expected value	For a given test, this is the ideal outcome predicted by the null hypothesis (e.g. a 1:1 ratio of heads to tails on fair coin flips)
